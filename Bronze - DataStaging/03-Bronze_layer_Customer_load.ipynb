{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "077a1651-2c26-4cd3-b91d-038c8c24db66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../01-Config/02-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baf2a0c1-2b5a-4a8a-a440-0dc938fa1b6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql.functions import current_timestamp, lit, input_file_name\n",
    "\n",
    "\n",
    "# Read customer file from source location\n",
    "customer_filepath = \"s3://tangirala/source-data/customer.csv\"\n",
    "df = spark.read.csv(\n",
    "    customer_filepath, \n",
    "    header=True, \n",
    "    inferSchema=True\n",
    ").withColumn(\n",
    "    \"ingestion_timestamp\", \n",
    "    current_timestamp()\n",
    ").withColumn(\n",
    "    \"filename\", \n",
    "    input_file_name()\n",
    ")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93b93b2f-f6c9-4474-92d6-2f346af4b29a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#wite data staging tables to bronze schema in snowflake\n",
    "\n",
    "df.write \\\n",
    "    .format(\"snowflake\") \\\n",
    "    .options(**snowflake_config) \\\n",
    "    .option(\"dbtable\", 'customer') \\\n",
    "    .option(\"sfDatabase\", 'ecommerce_db') \\\n",
    "    .option(\"sfSchema\", 'bronze') \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29c224ee-4eac-4fa1-a925-423a121bd3fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Archive processed files\n",
    "\n",
    "import datetime\n",
    "archive_folder = \"/dbfs/FileStore/archive-data/customer_data/\"\n",
    "archive_filepath = archive_folder +'_'+datetime.datetime.now().strftime(\"%Y%m%d%H%M%s\")\n",
    "dbutils.fs.mv(customer_filepath, archive_filepath)\n",
    "print(archive_filepath)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 432430608335461,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03-Bronze_layer_Customer_load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
